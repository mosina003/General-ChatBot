{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mosina.S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mosina.S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Mosina.S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mload_model(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchatbot\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchatbot_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(r\"D:\\chatbot\\chatbot_model.h5\")\n",
    "import json\n",
    "import random\n",
    "intents=json.loads(open(r\"D:\\chatbot\\intents.json\", encoding='utf8').read())\n",
    "words=pickle.load(open(r\"D:\\chatbot\\words.pkl\",\"rb\"))\n",
    "classes=pickle.load(open(r\"D:\\chatbot\\classes.pkl\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words=nltk.word_tokenize(sentence)\n",
    "    sentence_words=[lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    print(\"sentence_words\",sentence_words)\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" % w)\n",
    "    return np.array(bag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    p=bow(sentence, words, show_details=False)\n",
    "    print(\"p =\",p)\n",
    "    res=model.predict(np.array([p]))[0]\n",
    "    print(\"res=\",res)\n",
    "    ERROR_THRESHOLD=0.25\n",
    "    results=[[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    print(\"result=\",results)\n",
    "    #sort by strength\n",
    "    results.sort(key=lambda x:x[1], reverse=True)\n",
    "    result_list=[]\n",
    "    for r in results:\n",
    "        result_list.append({\"intent\":classes[r[0]], \"probability\": str(r[1])})\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents):\n",
    "    # Initialize result variable\n",
    "    result = \"I'm sorry, I didn't understand that.\"  # Default response if no match found\n",
    "\n",
    "    # Check if there are any intents recognized\n",
    "    if ints and len(ints) > 0:\n",
    "        tag = ints[0]['intent']  # Get the top intent\n",
    "        for i in intents['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                result = random.choice(i['responses'])  # Get a random response\n",
    "                break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(msg):\n",
    "    ints=predict_class(msg,model)\n",
    "    print(\"ints=\",ints)\n",
    "    res=getResponse(ints, intents)\n",
    "    print(\"chatbot response=\", res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flask-ngrok in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (0.0.25)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from flask-ngrok) (3.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from flask-ngrok) (2.31.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.8->flask-ngrok) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from requests->flask-ngrok) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from requests->flask-ngrok) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from requests->flask-ngrok) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from requests->flask-ngrok) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->Flask>=0.8->flask-ngrok) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (2.1.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyngrok in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (7.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from pyngrok) (6.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flask-cors in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (5.0.0)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from flask-cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.9->flask-cors) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.9->flask-cors) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.9->flask-cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Flask>=0.9->flask-cors) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->Flask>=0.9->flask-cors) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mosina.s\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-cors) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install flask-ngrok\n",
    "!pip install pyngrok\n",
    "!pip install flask-cors\n",
    "from flask import Flask\n",
    "from flask_cors import CORS\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request, Response\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask_cors import CORS\n",
    "  # Only call this once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x1d24e51f2c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Allow specific origins or allow all\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # Start Ngrok automatically\n",
    "CORS(app)\n",
    "CORS(app, resources={r\"/query/*\": {\"origins\": \"*\"}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Response, json\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    user_message = request.json.get('message')\n",
    "    response_data = {\"response\": chatbot_response(user_message)}\n",
    "    return Response(json.dumps(response_data), content_type='application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x1d24fc18e60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # This will start Ngrok automatically\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:03:59] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:03:59] \"GET / HTTP/1.1\" 200 -\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:4040\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:04:00] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:04:00] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py\", line 496, in _make_request\n",
      "    conn.request(\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py\", line 400, in request\n",
      "    self.endheaders()\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\http\\client.py\", line 1326, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\http\\client.py\", line 1085, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\http\\client.py\", line 1029, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py\", line 238, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D24EB333E0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D24EB333E0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1431, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask_ngrok.py\", line 70, in start_ngrok\n",
      "    ngrok_address = _run_ngrok()\n",
      "                    ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask_ngrok.py\", line 35, in _run_ngrok\n",
      "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D24EB333E0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "DEBUG:root:Received query: defnition+of+machine+learning\n",
      "DEBUG:root:Decrypted query: defnition of machine learning\n",
      "ERROR:__main__:Exception on /query/defnition+of+machine+learning [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask_cors\\extension.py\", line 194, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Local\\Temp\\ipykernel_23880\\3717011718.py\", line 15, in query_chatbot\n",
      "    response = chatbot_response(dec_msg)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Local\\Temp\\ipykernel_23880\\482732874.py\", line 2, in chatbot_response\n",
      "    ints=predict_class(msg,model)\n",
      "                           ^^^^^\n",
      "NameError: name 'model' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:04:08] \"\u001b[35m\u001b[1mGET /query/defnition+of+machine+learning HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:04:19] \"GET / HTTP/1.1\" 200 -\n",
      "DEBUG:root:Received query: what+is+ml\n",
      "DEBUG:root:Decrypted query: what is ml\n",
      "ERROR:__main__:Exception on /query/what+is+ml [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask_cors\\extension.py\", line 194, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Roaming\\Python\\Python312\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Local\\Temp\\ipykernel_23880\\3717011718.py\", line 15, in query_chatbot\n",
      "    response = chatbot_response(dec_msg)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mosina.S\\AppData\\Local\\Temp\\ipykernel_23880\\482732874.py\", line 2, in chatbot_response\n",
      "    ints=predict_class(msg,model)\n",
      "                           ^^^^^\n",
      "NameError: name 'model' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Oct/2024 23:04:29] \"\u001b[35m\u001b[1mGET /query/what+is+ml HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "@app.route(\"/\", methods=['GET'])\n",
    "def index():\n",
    "    return jsonify({\"health\": \"server is running successfully\"})\n",
    "\n",
    "def decrypt(msg):\n",
    "    string=msg\n",
    "    new_string=string.replace('+', \" \")\n",
    "    return new_string\n",
    "\n",
    "@app.route(\"/query/<sentence>\")\n",
    "def query_chatbot(sentence):\n",
    "    logging.debug(f\"Received query: {sentence}\")\n",
    "    dec_msg = decrypt(sentence)\n",
    "    logging.debug(f\"Decrypted query: {dec_msg}\")\n",
    "    response = chatbot_response(dec_msg)\n",
    "    logging.debug(f\"Response from chatbot: {response}\")\n",
    "    return jsonify({\"top\": {\"res\": response}})\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2655040766.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 49\u001b[1;36m\u001b[0m\n\u001b[1;33m    return result_list    return np.array(bag)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(r\"D:\\chatbot\\chatbot_model.h5\")\n",
    "import json\n",
    "import random\n",
    "intents=json.loads(open(r\"D:\\chatbot\\intents.json\", encoding='utf8').read())\n",
    "words=pickle.load(open(r\"D:\\chatbot\\words.pkl\",\"rb\"))\n",
    "classes=pickle.load(open(r\"D:\\chatbot\\classes.pkl\",\"rb\"))\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words=nltk.word_tokenize(sentence)\n",
    "    sentence_words=[lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    print(\"sentence_words\",sentence_words)\n",
    "    return sentence_words\n",
    "def bow(sentence,words,show_details=True):\n",
    "    #tokenize\n",
    "    sentence_words=clean_up_sentence(sentence)\n",
    "    #bow\n",
    "    bag=[0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if(w==s):\n",
    "                #assign 1 if current word is in vocabulary position\n",
    "                bag[i]=1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" %w)\n",
    "def predict_class(sentence, model):\n",
    "    p=bow(sentence, words, show_details=False)\n",
    "    print(\"p =\",p)\n",
    "    res=model.predict(np.array([p]))[0]\n",
    "    print(\"res=\",res)\n",
    "    ERROR_THRESHOLD=0.25\n",
    "    results=[[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    print(\"result=\",results)\n",
    "    #sort by strength\n",
    "    results.sort(key=lambda x:x[1], reverse=True)\n",
    "    result_list=[]\n",
    "    for r in results:\n",
    "        result_list.append({\"intent\":classes[r[0]], \"probability\": str(r[1])})\n",
    "    return result_list    return np.array(bag)  \n",
    "def getResponse(ints, intents):\n",
    "    # Initialize result variable\n",
    "    result = \"I'm sorry, I didn't understand that.\"  # Default response if no match found\n",
    "\n",
    "    # Check if there are any intents recognized\n",
    "    if ints and len(ints) > 0:\n",
    "        tag = ints[0]['intent']  # Get the top intent\n",
    "        for i in intents['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                result = random.choice(i['responses'])  # Get a random response\n",
    "                break\n",
    "\n",
    "    return result\n",
    "def chatbot_response(msg):\n",
    "    ints=predict_class(msg,model)\n",
    "    print(\"ints=\",ints)\n",
    "    res=getResponse(ints, intents)\n",
    "    print(\"chatbot response=\", res)\n",
    "    return res \n",
    "\n",
    "!pip install flask-ngrok\n",
    "!pip install pyngrok\n",
    "!pip install flask-cors\n",
    "from flask import Flask\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # This will allow your React app to make requests to Flask\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@app.route(\"/query/<sentence>\")\n",
    "def query_chatbot(sentence):\n",
    "    logging.debug(f\"Received query: {sentence}\")\n",
    "    dec_msg = decrypt(sentence)\n",
    "    logging.debug(f\"Decrypted query: {dec_msg}\")\n",
    "    response = chatbot_response(dec_msg)\n",
    "    logging.debug(f\"Response from chatbot: {response}\")\n",
    "    return jsonify({\"top\": {\"res\": response}}) \n",
    "from flask_cors import CORS\n",
    "\n",
    "# Allow specific origins or allow all\n",
    "CORS(app, resources={r\"/query/*\": {\"origins\": \"*\"}}) \n",
    "from flask import Response, json\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    user_message = request.json.get('message')\n",
    "    response_data = {\"response\": chatbot_response(user_message)}\n",
    "    return Response(json.dumps(response_data), content_type='application/json')\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # This will start Ngrok automatically\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\", methods=['GET'])\n",
    "def index():\n",
    "    return jsonify({\"health\": \"server is running successfully\"})\n",
    "\n",
    "def decrypt(msg):\n",
    "    string=msg\n",
    "    new_string=string.replace('+', \" \")\n",
    "    return new_string\n",
    "\n",
    "@app.route(\"/query/<sentence>\")\n",
    "def query_chatbot(sentence):\n",
    "    logging.debug(f\"Received query: {sentence}\")\n",
    "    dec_msg = decrypt(sentence)\n",
    "    logging.debug(f\"Decrypted query: {dec_msg}\")\n",
    "    response = chatbot_response(dec_msg)\n",
    "    logging.debug(f\"Response from chatbot: {response}\")\n",
    "    return jsonify({\"top\": {\"res\": response}})\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Response, json\n",
    "\n",
    "@app.route('/chat', methods=['GET'])\n",
    "def chat():\n",
    "    user_message = request.json.get('message')\n",
    "    logging.debug(f\"User message: {user_message}\")\n",
    "    if not user_message:\n",
    "        return Response(json.dumps({\"error\": \"No message provided\"}), status=400, content_type='application/json')\n",
    "\n",
    "    response_data = {\"response\": chatbot_response(user_message)}\n",
    "    return Response(json.dumps(response_data), content_type='application/json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # This will start Ngrok automatically\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\", methods=['GET'])\n",
    "def index():\n",
    "    return jsonify({\"health\": \"server is running successfully\"})\n",
    "\n",
    "def decrypt(msg):\n",
    "    string=msg\n",
    "    new_string=string.replace('+', \" \")\n",
    "    return new_string\n",
    "\n",
    "@app.route(\"/query/<sentence>\")\n",
    "def query_chatbot(sentence):\n",
    "    logging.debug(f\"Received query: {sentence}\")\n",
    "    dec_msg = decrypt(sentence)\n",
    "    logging.debug(f\"Decrypted query: {dec_msg}\")\n",
    "    response = chatbot_response(dec_msg)\n",
    "    logging.debug(f\"Response from chatbot: {response}\")\n",
    "    return jsonify({\"top\": {\"res\": response}})\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
